{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPRE1KOKnhFcA5ES8O6PIX8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","# !cp /content/gdrive/MyDrive/PPlusPlus/models/word_model.py /content/word_model.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c84V1WmDVKp","executionInfo":{"status":"ok","timestamp":1682330522098,"user_tz":-120,"elapsed":19148,"user":{"displayName":"Alex Meng","userId":"00783091975386351721"}},"outputId":"e594083a-2f91-4ccf-94f7-63b1cbc5bd66"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLKgHNn0cdLO"},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import time\n","\n","embed_size=256\n","hidden_size=512\n","num_layers=1\n","vocab_size=4987 \n","# https://www.youtube.com/watch?v=y2BaTt1fxJU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class DecoderRNN(nn.Module):\n","  def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n","    \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n","    super(DecoderRNN, self).__init__()\n","    # self.cat_embedding = nn.Embedding(n_cat, cat_embedding_size)  # (18, 32)\n","    self.embed = nn.Embedding(vocab_size, embed_size) \n","    # output, (h_n, c_n), input_size = cat_embedding_size+char_embedding_size (32+32=64)\n","    self.lstm = nn.LSTM(embed_size*2, hidden_size, num_layers, batch_first=True)\n","    self.linear = nn.Linear(hidden_size, vocab_size) \n","    self.init_weights()\n","  \n","  def init_weights(self):\n","    \"\"\"Initialize weights.\"\"\"\n","    self.embed.weight.data.uniform_(-0.1, 0.1)\n","    self.linear.weight.data.uniform_(-0.1, 0.1)\n","    self.linear.bias.data.fill_(0)\n","      \n","  def forward(self, features, captions):\n","    \"\"\"\n","    Decode image feature vectors and generates captions.\n","    features: vector\n","    captions: tensor\n","    lengths: hidden?\n","    \"\"\"\n","    # captions = captions.clone().detach().long() # Tensor: (12,)\n","    # print('captions: ', captions)  # device='cuda:0'\n","    embeddings = self.embed(captions)  # Tensor: (12, 256)\n","    # print('features.shape before cat: ', features.shape)  # \n","    # print('embeddings.shape before cat: ', embeddings.shape)  # torch.Size([12, 256])\n","    embeddings = torch.cat((features.repeat(12, 1), embeddings), 1).to(device)  # (12, 512)\n","    # print('embeddings.shape fed to lstm: ', embeddings.shape)  # torch.Size([12, 512])\n","    # output, (hidden, cell) = self.lstm(torch.concat([cat_emb, char_emb], dim=1))\n","    # Defaults to zeros if (h_0, c_0) is not provided.\n","    output, _ = self.lstm(embeddings)\n","    # print('output shape: ', output.shape)  # torch.Size([12, 512])\n","    predictions = self.linear(output)\n","    # print('predictions shape: ', predictions.shape)  # torch.Size([12, 4987])\n","    return torch.nn.functional.log_softmax(predictions, dim=1)\n","\n","  def sample(self, features, states=None):\n","    \"\"\"Samples captions for given image features (Greedy search).\"\"\"\n","    sampled_ids = []\n","    inputs = features.unsqueeze(1)\n","    with open(\"data/vocab.pkl\", 'rb') as f:\n","      vocab = pickle.load(f)  # a Vocabulary() from utils/build_vocab.py\n","    for i in range(20):                                      # maximum sampling length\n","      hiddens, states = self.lstm(inputs, states)          # (batch_size, 1, hidden_size), \n","\n","      # print(hiddens.size())\n","      # print(states[0].size(),states[1].size())\n","\n","      outputs = self.linear(hiddens.squeeze(1))            # (batch_size, vocab_size)\n","      predicted = outputs.max(1)[1]\n","\n","      # print(\"stuff\",type(predicted.data),predicted.data)\n","      # print(vocab.idx2word[1])\n","      # print(\"\\nNNASDFKLASDJF\\n\\n\",vocab.idx2word[predicted.data.cpu().numpy()[0]])\n","\n","      sampled_ids.append(predicted)\n","      inputs = self.embed(predicted)\n","      inputs = inputs.unsqueeze(1)                         # (batch_size, 1, embed_size)\n","\n","    # print(\"SAMPLED IDS\",sampled_ids.size())\n","    sampled_ids = torch.cat(sampled_ids, 0)                  # (batch_size, 20)\n","    return sampled_ids.squeeze()\n","\n","  def init_hidden(self):\n","    return torch.zeros(1, hidden_size)\n","\n","\n","def train(features, captions):\n","  # get a fresh hidden layer\n","  # hidden = lstm.initHidden()\n","  # zero the gradients\n","  optimizer.zero_grad()\n","  # run sequence;  def forward(self, features, captions)\n","  predictions = lstm(features, captions)\n","  # compute loss (NLLH)\n","  loss = criterion(predictions[:-1], captions[1:len(captions)])\n","  # perform backward pass\n","  loss.backward()\n","  # perform optimization\n","  optimizer.step()\n","  # return prediction and loss\n","  return loss.item()"]},{"cell_type":"markdown","source":["define dataset and dataloader following [this video](https://www.youtube.com/watch?v=PXOzkkB5eH0)"],"metadata":{"id":"9AHSejOYEnqC"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import pickle\n","\n","class ModelDataset(Dataset):\n","  def __init__(self, file_path):\n","    # data loading\n","    with open(file_path, 'rb') as f:\n","      self.data = pickle.load(f)\n","    self.n_samples = len(self.data)\n","  \n","  def __getitem__(self, index):\n","    # return a pair of feature and captions, allowing indexing\n","    return self.data[index][0], self.data[index][1]\n","  \n","  def __len__(self):\n","    return self.n_samples\n","\n","mydataset = ModelDataset(\"/content/gdrive/MyDrive/PPlusPlus/vg_data/vg_feat_cap_0.pkl\")\n","dataloader = DataLoader(dataset = mydataset, batch_size=1, num_workers=0, shuffle=True)\n"],"metadata":{"id":"6BtgfQhOEt3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# feature: tensor (1, 256); caption: tensor(12,)\n","i = 0\n","for feature, caption in dataloader:\n","  print(feature[0].shape, \"\\n\", caption[0], \"\\n\")\n","  i += 1\n","  if i > 1: break\n","# torch.Size([1, 256]) \n","# tensor([ 1, 10,  6, 11,  4, 12,  2,  0,  0,  0,  0,  0]) \n","# caption = torch.as_tensor(caption).to(device)\n","# print(caption)"],"metadata":{"id":"C64dkvr7NGF3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682257245929,"user_tz":-120,"elapsed":186,"user":{"displayName":"Alex Meng","userId":"00783091975386351721"}},"outputId":"fcf13f7b-50a4-4f5e-f48f-e6ed6a9b2796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 256]) \n"," tensor([  1,  25, 406, 751,  55,   2,   0,   0,   0,   0,   0,   0]) \n","\n","torch.Size([1, 256]) \n"," tensor([   1,    4, 1063,    6,    7,   55,    2,    0,    0,    0,    0,    0]) \n","\n"]}]},{"cell_type":"markdown","source":["continue train() model from epoch 26"],"metadata":{"id":"0MvxQMmeCNcI"}},{"cell_type":"code","source":["# load pretrained model and continue training\n","# model = TheModelClass(*args, **kwargs)\n","# model.load_state_dict(torch.load(PATH))\n","# model.eval()\n","lstm = DecoderRNN(embed_size=embed_size, hidden_size=hidden_size, \n","                  vocab_size=vocab_size, num_layers=num_layers).to(device)\n","lstm.load_state_dict(torch.load('/content/epoch25'))\n","lstm.eval()\n","lstm.train()\n","criterion = nn.NLLLoss(reduction='sum')\n","# learning rate\n","learning_rate = 0.0005\n","# optimizer\n","optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n","# training parameters\n","n_epoch = 25 \n","all_losses = []\n","total_loss = 0 \n","\n","start = time.time()\n","print(\"epochs\\tloss\\t\\t\\ttime(s)\")\n","for epoch in range(26, n_epoch+26):\n","  for feature, captions in dataloader:\n","    # feature = feature.to(device)  # .to(device) is redundant\n","    captions = captions.to(device)\n","    loss = train(feature[0], captions[0])\n","    total_loss += loss\n","\n","  print(epoch, \"\\t\", total_loss, \"\\t\", time.time() - start)  # 5.8m/epoch\n","  start = time.time()\n","  total_loss = 0\n","\n","torch.save(lstm.state_dict(), '/content/vg_word_decoder_50.pkl')  \n","# vg-decoder-5-3000.pkl, 6252kb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPv4hKnCfKqy","executionInfo":{"status":"ok","timestamp":1682266129982,"user_tz":-120,"elapsed":177514,"user":{"displayName":"Alex Meng","userId":"00783091975386351721"}},"outputId":"61866e1f-325e-4498-8b7e-16bead9925bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epochs\tloss\t\t\ttime(s)\n","26 \t 196406.3999903676 \t 177.18793272972107\n"]}]},{"cell_type":"code","source":["# train without loading pre-trained model\n","lstm = DecoderRNN(embed_size=embed_size, hidden_size=hidden_size, \n","                  vocab_size=vocab_size, num_layers=num_layers).to(device)\n","criterion = nn.NLLLoss(reduction='sum')\n","# learning rate\n","learning_rate = 0.0005\n","# optimizer\n","optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n","# training parameters\n","n_epoch = 25\n","# print_every = 5\n","all_losses = []\n","total_loss = 0 \n","\n","start = time.time()\n","print(\"epochs\\tloss\\t\\t\\ttime(s)\")\n","for epoch in range(1, n_epoch+1):\n","  for feature, captions in dataloader:\n","    # feature = feature.to(device)  # .to(device) redundant\n","    captions = captions.to(device)\n","    loss = train(feature[0], captions[0])\n","    total_loss += loss\n","\n","  print(epoch, \"\\t\", total_loss, \"\\t\", time.time() - start)  # 5.8m/epoch\n","  start = time.time()\n","  total_loss = 0\n","  # if epoch % print_every == 0:  # 850s(14.2m) for each 5 epoch\n","  #   # all_losses.append(total_loss / print_every)\n","  #   print(epoch, \"\\t\", total_loss, \"\\t\", time.time() - start)\n","  #   start = time.time()\n","  #   total_loss = 0\n","# save: torch.save(model.state_dict(), PATH)  \n","# torch.save(model, PATH)\n","torch.save(lstm.state_dict(), '/content/vg_word_decoder_25.pkl')\n","# torch.save(lstm, '/content/test_save')  # test_save.py: 22.65mb "],"metadata":{"id":"xgGLP5PoCM2C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44863c3e-8893-4358-e825-7ea53ae67976","executionInfo":{"status":"ok","timestamp":1682268562267,"user_tz":-120,"elapsed":882233,"user":{"displayName":"Alex Meng","userId":"00783091975386351721"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epochs\tloss\t\t\ttime(s)\n","1 \t 738013.8100529313 \t 182.07085394859314\n","2 \t 615120.0524843037 \t 178.58732175827026\n","3 \t 566254.86066176 \t 174.16399240493774\n","4 \t 523824.8683729768 \t 173.6789710521698\n","5 \t 488836.4067925513 \t 173.39287161827087\n"]}]},{"cell_type":"markdown","source":["# NOTES\n"],"metadata":{"id":"MzqwYB5hbaPO"}},{"cell_type":"code","source":["import torch\n","feat = torch.zeros(1, 256)\n","feat.repeat(12, 1).shap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgufr2mBl7F_","executionInfo":{"status":"ok","timestamp":1682160844739,"user_tz":-120,"elapsed":243,"user":{"displayName":"Alex Meng","userId":"00783091975386351721"}},"outputId":"7657beab-6c1b-4a80-e7da-049e6ada157d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 256])"]},"metadata":{},"execution_count":4}]}]}